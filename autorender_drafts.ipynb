{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from scipy.io import wavfile\n",
    "import dawdreamer as daw\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "SAMPLE_RATE = 44100\n",
    "BUFFER_SIZE = 512\n",
    "SERUM_PATH = r\"D:\\Serum_Render\\Serum_x64.dll\" # Place your Serum .dll here\n",
    "PRESETS_FOLDER = r\"D:\\Serum_Render\\bass_1\\presets\" # Place your Serum presets folder here\n",
    "OUT_FOLDER = r\"D:\\Serum_Render\\bass_1\\wav\" # Place the folder for your files here\n",
    "NOTES_DICT = {\n",
    "    \"C0\": 12,\n",
    "    \"C1\": 24,\n",
    "    \"C2\": 36,\n",
    "    \"C3\": 48,\n",
    "    \"C4\": 60,\n",
    "    \"C5\": 72,\n",
    "    \"C6\": 84\n",
    "}\n",
    "\n",
    "def get_filenames_and_paths(directory):\n",
    "    path = os.path.abspath(directory)\n",
    "    abspaths = [entry.path for entry in os.scandir(path) if entry.is_file()]\n",
    "    return abspaths\n",
    "\n",
    "def render_preset_in_notes(outpath):\n",
    "    for note_c, note_num in zip(NOTES_DICT.keys(), NOTES_DICT.values()):\n",
    "        serum.add_midi_note(note_num, 127, 0.0, 1.5) # arguments - note, velocity, start point, duration\n",
    "        engine.load_graph([(serum, [])])\n",
    "        engine.render(3.)\n",
    "        audio = engine.get_audio()\n",
    "        wavfile.write(f\"{outpath}-{note_c}.wav\", SAMPLE_RATE, audio.transpose())\n",
    "        serum.clear_midi()\n",
    "\n",
    "def render_presets(filepaths):\n",
    "    for presetpath in tqdm(filepaths, desc=\"Rendering Serum presets:\"):\n",
    "        serum.load_preset(presetpath)\n",
    "        presetname_orig = os.path.basename(presetpath)\n",
    "        presetname = os.path.splitext(presetname_orig)[0]\n",
    "        outpath = os.path.join(OUT_FOLDER, presetname)\n",
    "        render_preset_in_notes(outpath)\n",
    "\n",
    "filepaths = get_filenames_and_paths(PRESETS_FOLDER)\n",
    "\n",
    "engine = daw.RenderEngine(SAMPLE_RATE, BUFFER_SIZE)\n",
    "serum = engine.make_plugin_processor(\"serum\", SERUM_PATH)\n",
    "\n",
    "render_presets(filepaths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking the duplicates in folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import stat\n",
    "import hashlib \n",
    "from pathlib import Path \n",
    " \n",
    "file_path = r\"D:\\Serum_Render\\Data\\Batch 4 - Presets 0-50k\" \n",
    "\n",
    "list_of_files = os.walk(file_path) \n",
    " \n",
    "unique_files = dict() \n",
    "\n",
    "for root, folders, files in list_of_files: \n",
    "\n",
    "\t# Running a for loop on all the files \n",
    "\tfor file in files: \n",
    "\n",
    "\t\t# Finding complete file path \n",
    "\t\tfile_path = Path(os.path.join(root, file)) \n",
    "\n",
    "\t\t# Converting all the content of \n",
    "\t\t# our file into md5 hash. \n",
    "\t\tHash_file = hashlib.md5(open(file_path, 'rb').read()).hexdigest() \n",
    "\n",
    "\t\t# If file hash has already\n",
    "\t\t# been added we'll simply delete that file \n",
    "\t\tif Hash_file not in unique_files: \n",
    "\t\t\tunique_files[Hash_file] = file_path \n",
    "\t\telse:\n",
    "\t\t\tos.chmod(file_path, stat.S_IWRITE)\n",
    "\t\t\tos.remove(file_path)\n",
    "\t\t\tprint(f\"{file_path} has been deleted\") \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filtering MP3-s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('files_filtered.txt', 'r') as file:\n",
    "    filtered_files = [line.strip() for line in file]\n",
    "\n",
    "filtered_files_mp3_names = [file.replace(\".fxp\", \".mp3\")\n",
    "                      for file in filtered_files]\n",
    "\n",
    "new_files = []\n",
    "for mp3_file in filtered_files_mp3_names:\n",
    "    for i in range(7):\n",
    "        new_file = mp3_file.replace(\".mp3\", f\"_C{i}.mp3\")\n",
    "        new_files.append(new_file)\n",
    "        # print(new_file)\n",
    "\n",
    "# Specify the file path\n",
    "file_path = \"filtered_mp3-s.txt\"\n",
    "\n",
    "# Using \"with open\" syntax to automatically close the file\n",
    "with open(file_path, 'w') as file:\n",
    "    # Join the list elements into a single string with a newline character\n",
    "    data_to_write = '\\n'.join(new_files)\n",
    "    \n",
    "    # Write the data to the file\n",
    "    file.write(data_to_write)\n",
    "\n",
    "print(f\"The list has been written to {file_path}.\")\n",
    "\n",
    "# print(filtered_files_mp3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upload to Dropbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import dropbox\n",
    "from concurrent.futures import ThreadPoolExecutor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Инициализировать клиент Dropbox с токеном доступа\n",
    "ACCESS_TOKEN = \"sl.u.AFgVs81SPVmM2olywDGmw88ZSaHRiYtvIJ8kEKEONKCvEjPa03OcLcHKEGhD5g1UcYTnTE39ugtACxGbf7OKzc2RgG6-fPZNPSmDngwjBGiD9JbKwSjX6NhY6j1lYyTa35kILPH44vqF8om3mmD5SmI08BWkF9loVmZsqbqPNRoYptggpXRKEIIsxbscN3bKBqAfmWD-8YtNVgBaPzZsfTxXyAFLKTxuulOJ55LwQGkX8UI-b7LLk8qgZ-abpOcyFkT9lnbxrohgehVbwU54Fh9lvVZlH2fROwQ9AEPvdcoHTKaYNj6x_8ZobUsL_XFPy89RGSn-nIcydTQiUqwGbutOcEMoyGDYpsXtCp7EpuGTXZANn9g-3Kh_CDbFftNs4MVSXITvVseOUfqp4EG-5Oeq6Gem3Uc6omhBlp2Z-hESrW5PQf-QUJzeymiynHNJ_zcIpHfxTPlipKbbfW0gkNV27JxeQvKHAD0qQbDn2WtNdnOItBgeBaCtFJrllg3HJNDqoNys48PQY-8WNBtLvaCA7Z6N4jCE-IvVtu4jaX70XcQaVRghTYVbmZRLFWnRXyKfsqN88-UjN7J4_lw7vwyIbYsHX01i-exLl_QBDnDtHRbMDbv3m_coLWjLaD_OBJOCN4OmJuNT9xwCHSle7jq4hzu2dhf46UeuYjrEpTUMXsQ00wQAcZ6S1dVI0FcY8FcyMHMdXsYlDR_RmjN2Aryn5aAzSgC4UkAjD3A_uvTV9SrXBLk_8BWLYMq5Pv6-Nd1YHpeeDD66OrjALMer_xquJfa_HfGMlDRr5sOFyQEru2n8MYX3g7ny8zvJYj7c_-ZparNLhi8Nay7oiapUHhhrT886dFbOMN5njQYskP36nmpbZX9E6kLmXC3qzlRmZ1RZr4I91Gp8PhFxcpq3YCpPUw907MuN72MtC4RL6TZ3ovooeKByxza29fBMweu3kE30jPexMcIcKKWP-_1XC5bxXYY7u61_LGSeKYRqjAGUDivjU_LDJHEhJjgkl9mPtgTh_7exQRaev-byLEslfagAYlync2FLzzCXGKN9KOv6kKcMPJES9XPlpIxcG5q-9s_xnAO_iThCniXtEC8kkOpzZIrq7GsfhgPEuFm4_S6rQEIeHUKaahShobsodPu82fsuXFX5LZhoQrxxzY9XZGec2tPHUB5a1XFN1GVwjo7VmQC_hUzV8oczoCx5dNepnt4pJTi12rBC7xoVpHk8CDLLfnTwYD61duTZMJvcxOgEuVT3f3wqL6ZEIuNLoMh80mSSdIoNi_jtRKETi5-W1qaUGr_ty4qyG473juF0-8nmmA\"\n",
    "dbx = dropbox.Dropbox(ACCESS_TOKEN)\n",
    "\n",
    "# JAP_5K_PATH = \"/mnt/d2_nfs/datasets/naint_datasets/jp_music/jp_music_5k\"\n",
    "# SAMPLES_MERGED_ANNO_PATH = os.path.join(JAP_5K_PATH, \"anno/on_audio/samples_merged_anno.csv\")\n",
    "# AUDIO_DIR_PATH = os.path.join(JAP_5K_PATH, \"audio/samples\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python example using Dropbox API for chunked upload\n",
    "# import dropbox\n",
    "\n",
    "def upload_large_file(dbx, file_path, target_path):\n",
    "    with open(file_path, 'rb') as f:\n",
    "        file_size = os.path.getsize(file_path)\n",
    "        chunk_size = 4 * 1024 * 1024  # 4MB chunks\n",
    "        if file_size <= chunk_size:\n",
    "            print(dbx.files_upload(f.read(), target_path))\n",
    "        else:\n",
    "            upload_session_start_result = dbx.files_upload_session_start(f.read(chunk_size))\n",
    "            cursor = dropbox.files.UploadSessionCursor(session_id=upload_session_start_result.session_id, offset=f.tell())\n",
    "            commit = dropbox.files.CommitInfo(path=target_path)\n",
    "            while f.tell() < file_size:\n",
    "                if (file_size - f.tell()) <= chunk_size:\n",
    "                    print(dbx.files_upload_session_finish(f.read(chunk_size), cursor, commit))\n",
    "                else:\n",
    "                    dbx.files_upload_session_append_v2(f.read(chunk_size), cursor)\n",
    "                    cursor.offset = f.tell()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upload_large_file(dbx, \"D:\\Serum_Render\\test_zip\\test_zip.zip\", \"\\test_zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Получаем список файлов на Dropbox\n",
    "def list_dropbox_files(folder):\n",
    "    files = []\n",
    "    try:\n",
    "        result = dbx.files_list_folder(folder)\n",
    "        files.extend(result.entries)\n",
    "        while result.has_more:\n",
    "            result = dbx.files_list_folder_continue(result.cursor)\n",
    "            files.extend(result.entries)\n",
    "    except dropbox.exceptions.ApiError as err:\n",
    "        print(f'Ошибка при получении списка файлов: {err}')\n",
    "    return files\n",
    "\n",
    "# Функция для загрузки одного файла\n",
    "def upload_file(local_path, dropbox_path):\n",
    "    with open(local_path, 'rb') as f:\n",
    "        print(f'Загрузка {local_path} на {dropbox_path}')\n",
    "        try:\n",
    "            dbx.files_upload(f.read(), dropbox_path, mode=dropbox.files.WriteMode('overwrite'))\n",
    "            print(f'Файл {local_path} успешно загружен.')\n",
    "        except dropbox.exceptions.ApiError as err:\n",
    "            print(f'Ошибка загрузки файла {local_path}: {err}')\n",
    "\n",
    "# Функция для обработки батча задач\n",
    "def process_batch(batch):\n",
    "    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:\n",
    "        executor.map(lambda p: upload_file(*p), batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_file = r\"D:\\Serum_Render\\outputs_test.zip\"\n",
    "upload_file(test_file, \"/samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# local_directory = AUDIO_DIR_PATH\n",
    "# dropbox_directory = '/My Japanese Datasets'\n",
    "\n",
    "local_directory = \"D:\\Serum_Render\\outputs_test\"\n",
    "# dropbox_directory = '/music'\n",
    "dropbox_directory = '/music'\n",
    "\n",
    "# Список файлов в указанной папке на Dropbox\n",
    "dropbox_files = list_dropbox_files(dropbox_directory)\n",
    "dropbox_file_names = {file.name for file in dropbox_files if isinstance(file, dropbox.files.FileMetadata)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Размер батча\n",
    "batch_size = 10\n",
    "MAX_WORKERS = 4\n",
    "\n",
    "# Проходим по всем файлам в локальной папке и обрабатываем их батчами\n",
    "batch = []\n",
    "for file_info in os.scandir(local_directory):\n",
    "    filename = file_info.name\n",
    "    local_path = file_info.path\n",
    "\n",
    "    # Получаем относительный путь для сохранения на Dropbox\n",
    "    relative_path = os.path.relpath(local_path, local_directory)\n",
    "    dropbox_path = os.path.join(dropbox_directory, relative_path)\n",
    "\n",
    "    # Проверяем, существует ли файл на Dropbox\n",
    "    if filename in dropbox_file_names:\n",
    "        print(f'Файл {filename} уже загружен, пропуск...')\n",
    "        continue\n",
    "\n",
    "    # Добавляем задачу в текущий батч\n",
    "    batch.append((local_path, dropbox_path))\n",
    "\n",
    "    # Если батч достиг нужного размера, обрабатываем его\n",
    "    if len(batch) >= batch_size:\n",
    "        print(f'Обработка батча из {len(batch)} файлов.')\n",
    "        process_batch(batch)\n",
    "        batch.clear()\n",
    "\n",
    "        break\n",
    "\n",
    "# Обрабатываем оставшиеся файлы в последнем батче\n",
    "if batch:\n",
    "    print(f'Обработка последнего батча из {len(batch)} файлов.')\n",
    "    process_batch(batch)\n",
    "\n",
    "print('Загрузка завершена!')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "midi2audio_byvst",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
